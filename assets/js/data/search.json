[ { "title": "Spring三级缓存决循环依赖", "url": "/posts/2023033001/", "categories": "", "tags": "Java", "date": "2023-03-30 10:12:00 +0000", "snippet": "假设A和B的定义如下：public class A { private B b; public A(B b) { this.b = b; }}public class B { private A a; public B(A a) { this.a = a; }}当Spring容器启动时，它会先创建A实例，但是在创建A实例的过程中...", "content": "假设A和B的定义如下：public class A { private B b; public A(B b) { this.b = b; }}public class B { private A a; public B(A a) { this.a = a; }}当Spring容器启动时，它会先创建A实例，但是在创建A实例的过程中发现需要依赖B实例，因此Spring会创建B实例并注入到A实例中，如下所示：1.创建A实例，发现需要B实例。2.创建B实例，并将其放入earlySingletonObjects缓存中。3.在创建B实例的过程中，发现需要A实例。因为A实例已经在第1步中创建了，因此可以直接从singletonObjects缓存中获取A实例，并将其注入到B实例中。4.将B实例放入singletonObjects缓存中。5.将A实例放入singletonObjects缓存中。这样，Spring就成功地解决了A和B的循环依赖问题。在整个过程中，Spring使用了三级缓存来保存Bean实例，通过提前暴露Bean实例的方式来解决循环依赖的问题。需要注意的是，如果A和B的作用域是prototype，则无法使用三级缓存来解决循环依赖的问题。" }, { "title": "Java文档", "url": "/posts/2022111901/", "categories": "", "tags": "Java", "date": "2022-11-19 10:12:00 +0000", "snippet": "线程池线程池7个参数说明： corePoolSize（核心线程数）：线程池中会维护一个最小的线程数量，即使这些线程处理空闲状态，他们也不会被销毁，除非设置了allowCoreThreadTimeOut。这里的最小线程数量即是corePoolSize。任务提交到线程池后，首先会检查当前线程数是否达到了corePoolSize，如果没有达到的话，则会创建一个新线程来处理这个任务。 ...", "content": "线程池线程池7个参数说明： corePoolSize（核心线程数）：线程池中会维护一个最小的线程数量，即使这些线程处理空闲状态，他们也不会被销毁，除非设置了allowCoreThreadTimeOut。这里的最小线程数量即是corePoolSize。任务提交到线程池后，首先会检查当前线程数是否达到了corePoolSize，如果没有达到的话，则会创建一个新线程来处理这个任务。 maximumPoolSize（最大线程数）：当前线程数达到corePoolSize后，如果继续有任务被提交到线程池，会将任务缓存到工作队列中。如果队列也已满，则会去创建一个新线程来出来这个处理。线程池不会无限制的去创建新线程，它会有一个最大线程数量的限制，这个数量即由maximunPoolSize指定。 keepAliveTime（空闲线程存活时间）：一个线程如果处于空闲状态，并且当前的线程数量大于corePoolSize，那么在指定时间后，这个空闲线程会被销毁，这里的指定时间由keepAliveTime来设定。 unit（单位）：空闲线程存活时间单位 workQueue（工作队列）：新任务被提交后，会先进入到此工作队列中，任务调度时再从队列中取出任务。jdk中提供了四种工作队列： Queue 描述 ArrayBlockingQueue 基于数组的有界阻塞队列，按FIFO排序。新任务进来后，会放到该队列的队尾，有界的数组可以防止资源耗尽问题。当线程池中线程数量达到corePoolSize后，再有新任务进来，则会将任务放入该队列的队尾，等待被调度。如果队列已经是满的，则创建一个新线程，如果线程数量已经达到maxPoolSize，则会执行拒绝策略。 LinkedBlockingQuene 基于链表的无界阻塞队列（其实最大容量为Interger.MAX），按照FIFO排序。由于该队列的近似无界性，当线程池中线程数量达到corePoolSize后，再有新任务进来，会一直存入该队列，而基本不会去创建新线程直到maxPoolSize（很难达到Interger.MAX这个数），因此使用该工作队列时，参数maxPoolSize其实是不起作用的。 SynchronousQuene 一个不缓存任务的阻塞队列，生产者放入一个任务必须等到消费者取出这个任务。也就是说新任务进来时，不会缓存，而是直接被调度执行该任务，如果没有可用线程，则创建新线程，如果线程数量达到maxPoolSize，则执行拒绝策略。 PriorityBlockingQueue 具有优先级的无界阻塞队列，优先级通过参数Comparator实现。 threadFactory（线程工厂）：有时需要对线程池中创建的线程属性进行定制化，这时就得需要配置ThreadFactory线程工厂。 handler（拒绝策略）：当工作队列中的任务已到达最大限制，并且线程池中的线程数量也达到最大限制，这时如果有新任务提交进来，该如何处理呢。这里的拒绝策略，就是解决这个问题的。jdk中提供了4中拒绝策略： CallerRunsPolicy 该策略下，在调用者线程中直接执行被拒绝任务的run方法，除非线程池已经shutdown，则直接抛弃任务。 AbortPolicy 该策略下，直接丢弃任务，并抛出RejectedExecutionException异常。 DiscardPolicy 该策略下，直接丢弃任务，什么都不做。 DiscardOldestPolicy 该策略下，抛弃进入队列最早的那个任务，然后尝试把这次拒绝的任务放入队列。 " }, { "title": "ubuntu安装ngrok", "url": "/posts/2022041901/", "categories": "", "tags": "ngrok", "date": "2022-04-19 02:52:00 +0000", "snippet": "安装goapt-get install golang下载ngrok源码git clone https://github.com/inconshreveable/ngrok.git配置环境变量sudo vim /etc/profileexport GOPATH=/usr/local/goexport PATH=$PATH:$GOPATH/binexport NGROK_DOMAIN=\"m9d2...", "content": "安装goapt-get install golang下载ngrok源码git clone https://github.com/inconshreveable/ngrok.git配置环境变量sudo vim /etc/profileexport GOPATH=/usr/local/goexport PATH=$PATH:$GOPATH/binexport NGROK_DOMAIN=\"m9d2.cn\"生成自签名证书openssl genrsa -out base.key 2048openssl req -new -x509 -nodes -key base.key -days 10000 -subj \"/CN=$NGROK_DOMAIN\" -out base.pemopenssl genrsa -out server.key 2048openssl req -new -key server.key -subj \"/CN=$NGROK_DOMAIN\" -out server.csropenssl x509 -req -in server.csr -CA base.pem -CAkey base.key -CAcreateserial -days 10000 -out server.crt替换证书cp base.pem assets/client/tls/ngrokroot.crtcp server.crt assets/server/tls/snakeoil.crtcp server.key assets/server/tls/snakeoil.key编译服务端make release-server启动./ngrokd -tlsKey=\"../assets/server/tls/snakeoil.key\" -tlsCrt=\"../assets/server/tls/snakeoil.crt\" -domain=\"m9d2.cn\" -httpAddr=\":8000\" -httpsAddr=\":8001\" &amp;设置为系统服务[Unit]Description=ngrokAfter=network.target[Service]ExecStart=/home/ubuntu/ngrok/bin/ngrokd -tlsKey=\"/home/ubuntu/ngrok/assets/server/tls/snakeoil.key\" -tlsCrt=\"/home/ubuntu/ngrok/assets/server/tls/snakeoil.crt\" -domain=\"m9d2.cn\" -httpAddr=\":1000\" -httpsAddr=\":1001\"[Install]WantedBy=multi-user.target编译客户端32位linux客户端: GOOS=linux GOARCH=386 make release-client64位linux客户端: GOOS=linux GOARCH=amd64 make release-client32位windows客户端: GOOS=windows GOARCH=386 make release-client64位windows客户端: GOOS=windows GOARCH=amd64 make release-client32位mac平台客户端:GOOS=darwin GOARCH=386 make release-client64位mac平台客户端:GOOS=darwin GOARCH=amd64 make release-clientARM平台linux客户端: GOOS=linux GOARCH=arm make release-client设置本地客户端windows配置ngrok.cfgserver_addr: \"m9d2.cn:4443\"trust_host_root_certs: false启动httpngrok.exe -subdomain=ngrok -config=ngrok.cfg 80tcpngrok.exe -proto=tcp -config=ngrok.cfg start ssh" }, { "title": "mysql8.0开启远程访问权限", "url": "/posts/2022030802/", "categories": "", "tags": "mysql", "date": "2022-03-08 08:54:00 +0000", "snippet": "1.设置密码ALTER USER 'root'@'localhost' IDENTIFIED BY '123456';2.修改hostupdate user set host='%' where user='root';3.刷新权限flush privileges;", "content": "1.设置密码ALTER USER 'root'@'localhost' IDENTIFIED BY '123456';2.修改hostupdate user set host='%' where user='root';3.刷新权限flush privileges;" }, { "title": "gem 添加国内源", "url": "/posts/2022030801/", "categories": "", "tags": "ruby", "date": "2022-03-08 08:53:00 +0000", "snippet": "查看当前使用的源地址gem sourcesgem 删除默认源命令gem sources --remove https://rubygems.org/gem 添加国内源gem sources -a https://gems.ruby-china.com/###gem sources --add https://mirrors.tuna.tsinghua.edu.cn/rubygems/检测方法...", "content": "查看当前使用的源地址gem sourcesgem 删除默认源命令gem sources --remove https://rubygems.org/gem 添加国内源gem sources -a https://gems.ruby-china.com/###gem sources --add https://mirrors.tuna.tsinghua.edu.cn/rubygems/检测方法gem sources -l更新源的缓存gem sources -u" }, { "title": "Centos7下yum安装mongodb", "url": "/posts/2021112201/", "categories": "", "tags": "mongodb", "date": "2021-11-22 02:12:00 +0000", "snippet": "1.创建mongo repo源vim /etc/yum.repos.d/mongodb.repo2.把下面的内容复制到文件中 保存退出[mongodb-org]name=MongoDB Repositorybaseurl=http://mirrors.aliyun.com/mongodb/yum/redhat/$releasever/mongodb-org/5.0/x86_64/gpgche...", "content": "1.创建mongo repo源vim /etc/yum.repos.d/mongodb.repo2.把下面的内容复制到文件中 保存退出[mongodb-org]name=MongoDB Repositorybaseurl=http://mirrors.aliyun.com/mongodb/yum/redhat/$releasever/mongodb-org/5.0/x86_64/gpgcheck=0enabled=13.安装mongoyum -y install mongodb-org4.修改 mongod.conf 配置文件vim /etc/mongod.conf5.启动mongo启动mongodb ：systemctl start mongod.service停止mongodb ：systemctl stop mongod.service查到mongodb的状态：systemctl status mongod.service添加到开机启动：systemctl enable mongod.service" }, { "title": "查看linux服务器磁盘空间占用情况", "url": "/posts/2021110901/", "categories": "", "tags": "linux", "date": "2021-11-09 03:12:00 +0000", "snippet": "1、查看磁盘空间占用df -h2、查看当前目录内文件夹的大小du -h --max-depth=1 -h或–human-readable 以K，M，G为单位，提高信息的可读性。 –max-depth=目录层数 超过指定层数的目录后，予以忽略。", "content": "1、查看磁盘空间占用df -h2、查看当前目录内文件夹的大小du -h --max-depth=1 -h或–human-readable 以K，M，G为单位，提高信息的可读性。 –max-depth=目录层数 超过指定层数的目录后，予以忽略。" }, { "title": "filebeat自定义索引规则", "url": "/posts/2021061101/", "categories": "", "tags": "filebeat", "date": "2021-06-11 10:12:00 +0000", "snippet": "filebeat.yml配置- type: log fields: source: basesetup.ilm.enabled: falsesetup.template.overwrite: truesetup.template.name: \"filebeat\"setup.template.pattern: \"filebeat-*\"setup.template.enabled: tr...", "content": "filebeat.yml配置- type: log fields: source: basesetup.ilm.enabled: falsesetup.template.overwrite: truesetup.template.name: \"filebeat\"setup.template.pattern: \"filebeat-*\"setup.template.enabled: trueoutput.elasticsearch: # Array of hosts to connect to. hosts: [\"127.0.0.1:9200\"] index: \"test-%{[fields.source]}-*\" indices: - index: \"test-base-%{+yyyy.MM.dd}-00001\" when.equals: fields.source: \"base\"" }, { "title": "spring boot项目自定义数据源，mybatisplus分页、逻辑删除无效解决方法", "url": "/posts/2020041601/", "categories": "", "tags": "java", "date": "2021-04-16 06:26:00 +0000", "snippet": "Spring Boot项目中数据源的配置可以通过两种方式实现：1.application.yml或者application.properties配置2.注入DataSource及SqlSessionFactory两个Bean通过第二种方式配置数据源则按照MybatisPlus官方文档使用分页及逻辑删除插件会无效，解决思路是在初始化SqlSessionFactory将插件设置进去/** * 逻...", "content": "Spring Boot项目中数据源的配置可以通过两种方式实现：1.application.yml或者application.properties配置2.注入DataSource及SqlSessionFactory两个Bean通过第二种方式配置数据源则按照MybatisPlus官方文档使用分页及逻辑删除插件会无效，解决思路是在初始化SqlSessionFactory将插件设置进去/** * 逻辑删除插件 */@Beanpublic GlobalConfig globalConfig(){ GlobalConfig globalConfig=new GlobalConfig(); GlobalConfig.DbConfig dbConfig=new GlobalConfig.DbConfig(); dbConfig.setLogicDeleteValue(\"Y\"); dbConfig.setLogicNotDeleteValue(\"N\"); globalConfig.setDbConfig(dbConfig); globalConfig.setSqlInjector(new LogicSqlInjector()); return globalConfig;}/** * 分页插件 */@Beanpublic PaginationInterceptor paginationInterceptor(){ PaginationInterceptor paginationInterceptor=new PaginationInterceptor(); paginationInterceptor.setDialectType(DbType.MYSQL.getDb()); return paginationInterceptor;}@Bean(name = \"sqlSessionFactory\")public SqlSessionFactory sqlSessionFactory()throws Exception{ logger.info(\"初始化SqlSessionFactory\"); String mapperLocations=\"classpath:mybatis/mapper/**/*.xml\"; String configLocation=\"classpath:mybatis/mybatis-config.xml\"; MybatisSqlSessionFactoryBean sqlSessionFactory=new MybatisSqlSessionFactoryBean(); sqlSessionFactory.setDataSource(dataSource()); //数据源 ResourcePatternResolver resolver=new PathMatchingResourcePatternResolver(); sqlSessionFactory.setMapperLocations(resolver.getResources(mapperLocations)); sqlSessionFactory.setConfigLocation(resolver.getResource(configLocation)); sqlSessionFactory.setTypeAliasesPackage(\"com.innjoy.pms.order.infrastructure.domain.model\"); sqlSessionFactory.setGlobalConfig(globalConfig()); sqlSessionFactory.setPlugins(new Interceptor[]{paginationInterceptor()}); return sqlSessionFactory.getObject();}" }, { "title": "acme.sh 自动替换ssl证书", "url": "/posts/2020030401/", "categories": "", "tags": "shell", "date": "2021-03-04 02:24:00 +0000", "snippet": "简介acme.sh是github的开源项目，项目地址：https://github.com/acmesh-official/acme.sh该项目实现了从letsencrypt生成免费的证书并且将证书替换到nginx、Apache等服务器一、安装1.命令安装curl https://get.acme.sh | sh -s email=my@example.com2.把 acme.sh 安装到...", "content": "简介acme.sh是github的开源项目，项目地址：https://github.com/acmesh-official/acme.sh该项目实现了从letsencrypt生成免费的证书并且将证书替换到nginx、Apache等服务器一、安装1.命令安装curl https://get.acme.sh | sh -s email=my@example.com2.把 acme.sh 安装到你的 home 目录下:~/.acme.sh/并创建 一个 bash 的 alias, 方便你的使用: alias acme.sh=~/.acme.sh/acme.sh3.自动为你创建 cronjob, 每天 0:00 点自动检测所有的证书, 如果快过期了, 需要更新, 则会自动更新证书.二、生成证书acme.sh 实现了 acme 协议支持的所有验证协议. 一般有两种方式验证: http 和 dns 验证.这里使用 dns 验证 以DNSPod.cn为列1.首先设置API Key跟ID环境变量export DP_Id=\"1234\"export DP_Key=\"sADDsdasdgdsf\"2.生成证书acme.sh --issue --dns dns_dp -d example.com DP_Id跟DP_Key被保存~/.acme.sh/account.conf并在需要时被重用 –debug 添加改参数可打印出详细日志 其他域名供应商参考：https://github.com/acmesh-official/acme.sh/wiki/dnsapi三、安装证书acme.sh --install-cert -d example.com \\--key-file /home/ubuntu/certificate/example.key \\--fullchain-file /home/ubuntu/certificate/example.pem \\--reloadcmd \"sudo nginx -s reload\" -d：域名 –key-file：nginx ssl证书指向地址 –fullchain-file：nginx ssl证书指向地址四、更新证书目前证书在 60 天以后会自动更新, 你无需任何操作. 今后有可能会缩短这个时间, 不过都是自动的, 你不用关心.五、更新 acme.sh目前由于 acme 协议和 letsencrypt CA 都在频繁的更新, 因此 acme.sh 也经常更新以保持同步.升级 acme.sh 到最新版 :acme.sh --upgrade如果你不想手动升级, 可以开启自动升级:acme.sh --upgrade --auto-upgrade" }, { "title": "Kafka集群搭建过程", "url": "/posts/2020052301/", "categories": "", "tags": "Kafka", "date": "2020-05-23 10:37:00 +0000", "snippet": " 准备三台服务器，分别命名为server1(10.7.16.108)、server2(10.7.16.144)、server3(10.7.16.135) 环境要求 jdk8 系统centos7.3一、搭建zookeeper集群 三个节点都要下载配置1.下载zookeeper$ cd /home/innjoy/zookeeper$ wget http://mirror.bit.edu....", "content": " 准备三台服务器，分别命名为server1(10.7.16.108)、server2(10.7.16.144)、server3(10.7.16.135) 环境要求 jdk8 系统centos7.3一、搭建zookeeper集群 三个节点都要下载配置1.下载zookeeper$ cd /home/innjoy/zookeeper$ wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz$ cd zookeeper-3.4.14$ cp conf/zoo_sample.cfg conf/zoo.cfg2.修改zookeeper配置文件$ vi /conf/zoo.cfg增加下面配置信息dataLogDir=/home/innjoy/zookeeper/logsdataDir=/home/innjoy/zookeeper/dataserver.1= 10.7.16.108:2888:3888server.2= 10.7.16.144:2888:3888server.3= 10.7.16.135:2888:38883.创建相关目录，三台节点都需要$ mkdir -p /home/innjoy/zookeeper/zookeeper-3.4.14/{logs,data}4.创建ServerID标识 除了修改zoo.cfg配置文件外,zookeeper集群模式下还要配置一个myid文件,这个文件需要放在dataDir目录下。在192.168.1.148服务器上面创建myid文件，并设置值为1$ echo \"1\" &gt; /home/innjoy/zookeeper/data/myid在192.168.1.149服务器上面创建myid文件，并设置值为2$ echo \"2\" &gt; /home/innjoy/zookeeper/data/myid在192.168.1.150服务器上面创建myid文件，并设置值为3$ echo \"3\" &gt; /home/innjoy/zookeeper/data/myid5.启动每个服务器上面的zookeeper节点分别在3台节点执行启动命令$ ./bin/zkServer.sh start查看节点zookeeper状态$ ./bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /home/innjoy/zookeeper/zookeeper-3.4.14/bin/../conf/zoo.cfgMode: leader二、搭建kafka集群1.下载kafka 三个节点都要下载配置$ cd /home/innjoy/kafka$ wget http://mirror.bit.edu.cn/apache/kafka/2.2.0/kafka_2.11-2.2.0.tgz2.修改kafka配置文件$ cd kafka_2.11-2.2.0/config$ vi server.properties需要修改的内容如下：# The id of the broker. This must be set to a unique integer for each brokerbroker.id=2# A comma separated list of directories under which to store log fileslog.dirs=/home/innjoy/kafka/data# Zookeeper connection stringzookeeper.connect=10.7.16.108:2181,10.7.16.144:2192,10.7.16.135:21813.启动kafka$ ./kafka-server-start.sh -daemon ../config/server.properties4.验证是否启动kafka$ jps63938 Kafka62840 QuorumPeerMain63982 Jps" }, { "title": "Ubuntu Server 配置 Shadowsocks-libev 服务端", "url": "/posts/2020052202/", "categories": "", "tags": "Shadowsocks", "date": "2020-05-23 10:37:00 +0000", "snippet": " 官方文档：https://github.com/shadowsocks/shadowsocks-libev#debian–ubuntu安装依赖及软件$ sudo apt-get install software-properties-common -y$ sudo add-apt-repository ppa:max-c-lv/shadowsocks-libev -y$ sudo apt...", "content": " 官方文档：https://github.com/shadowsocks/shadowsocks-libev#debian–ubuntu安装依赖及软件$ sudo apt-get install software-properties-common -y$ sudo add-apt-repository ppa:max-c-lv/shadowsocks-libev -y$ sudo apt-get update$ sudo apt install shadowsocks-libev配置config.json$ sudo vim /etc/shadowsocks-libev/config.json 参考如下配置内容{ \"server\":\"0.0.0.0\", \"server_port\":8488, \"local_port\":1080, \"password\":\"123456\", \"timeout\":60, \"method\":\"aes-256-cfb\"}启动服务# Start the service$ sudo /etc/init.d/shadowsocks-libev start # for sysvinit, or$ sudo systemctl start shadowsocks-libev # for systemd重启服务$ sudo systemctl restart shadowsocks-libev 查看服务状态$ sudo systemctl status shadowsocks-libev " }, { "title": "v2ray帮助文档", "url": "/posts/2020052201/", "categories": "", "tags": "v2ray", "date": "2020-05-22 10:12:00 +0000", "snippet": "V2Ray简介V2Ray是近几年十分流行的网络工具，其功能强大，用途不限于突破防火墙，但因其能有效翻墙而广为人知。V2Ray有如下大放异彩的特点： 开源。V2Ray是Project V的核心工具，源代码开源； 多协议支持。传输层支持TCP、mKCP、WebSocket等，上层协议支持Socks、Shadowsocks、以及自定义的VMess等； 多入口和多出口。V2Ray可同时支持多个...", "content": "V2Ray简介V2Ray是近几年十分流行的网络工具，其功能强大，用途不限于突破防火墙，但因其能有效翻墙而广为人知。V2Ray有如下大放异彩的特点： 开源。V2Ray是Project V的核心工具，源代码开源； 多协议支持。传输层支持TCP、mKCP、WebSocket等，上层协议支持Socks、Shadowsocks、以及自定义的VMess等； 多入口和多出口。V2Ray可同时支持多个入站和出站协议，每个协议独立工作； 多平台支持。原生支持Windows、Linux、MacOS三大常用平台，安卓、iOS两大移动平台有丰富的第三方工具； 隐蔽性。V2Ray流量可伪装成网页流量，更难被检测和干扰。与另一个知名的翻墙工具Shadowsocks(R)相比，V2ray和SSR区别在于： V2Ray是一个框架/平台，而Shadowsocks(R)是一个代理工具； V2Ray功能强大配置复杂，Shadowsocks(R)简单易用； V2Ray性能更好，协议支持更完善。一句话总结：V2Ray更好更强大，但更难上手和用好安卓手机安装V2Ray客户端1、下载v2rayNG_1.2.6.apk并安装，打开APP v2rayNG_1.6.25.apk 下载地址2、点击右上角+按钮，然后点击从剪切板导入 需要提前复制url3、点击右下角灰色的V按钮，如下图所示则说明vpn连接成功" } ]
